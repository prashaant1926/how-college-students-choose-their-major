# Information Saturation Paradox Test - Experiment Plan

## Core Research Question
Does providing minimal, curated information lead to better major choice outcomes than comprehensive information packages?

## Assumption Being Challenged
**Literature assumes**: Providing more or better information about majors and career outcomes improves decision quality.

## Hypothesis
Students given minimal, curated information will make better major choices than students given comprehensive information packages.

## Experimental Design
- **Study Type**: 3x3 factorial design randomized controlled trial
- **Sample Size**: 360 students  
- **Factors**: Information load (minimal/moderate/comprehensive) x Format (text/visualizations/video)
- **Timeline**: 24 months total (2 months setup, 4 months intervention, 18 months follow-up)

## Treatment Conditions

### Information Load Levels:
1. **Minimal**: 3 key facts per major (core requirements, typical career paths, median salary)
2. **Moderate**: 10-12 facts per major (above + prerequisites, skills developed, job outlook, alumni outcomes)  
3. **Comprehensive**: 25+ facts per major (above + detailed curriculum, faculty profiles, research opportunities, industry trends, detailed salary ranges)

### Information Formats:
1. **Text**: Written descriptions and bulleted facts
2. **Visualizations**: Infographics, charts, and visual summaries
3. **Video**: 5-15 minute video presentations with student testimonials

## Primary Outcome Measures
1. **Decision Satisfaction** (6-month and 18-month follow-up)
   - Satisfaction with Major Scale (SWMS)
   - Major choice confidence ratings
2. **Academic Fit** 
   - GPA maintenance in chosen major
   - Course engagement metrics
3. **Career Alignment**
   - Career goals-major alignment assessment
   - Post-graduation path satisfaction

## Secondary Outcome Measures
1. **Decision Process Quality**
   - Decision time and deliberation patterns
   - Cognitive load during decision process
   - Choice certainty and regret measures
2. **Information Processing**
   - Information attention patterns (eye-tracking subset)
   - Memory for provided information
   - Use of external information sources

## Success Criteria
- **Primary**: Inverse relationship between information load and decision satisfaction (Î² < -0.3)
- **Secondary**: Lower cognitive load and higher confidence in minimal information condition
- **Effect Size Target**: Cohen's d > 0.5 for satisfaction differences between minimal and comprehensive conditions

## Milestones & Implementation

### Phase 1: Setup (Months 1-2)
- [x] IRB approval for human subjects research
- [x] Develop information packages for all 9 conditions
- [x] Create assessment instruments and online platform
- [x] Recruit participant pool from incoming students

### Phase 2: Intervention (Months 3-6)  
- [ ] Randomize students to conditions
- [ ] Deliver information packages during major exploration period
- [ ] Track decision processes and timing
- [ ] Collect immediate post-decision assessments

### Phase 3: Short-term Follow-up (Months 7-12)
- [ ] 6-month satisfaction and academic performance assessment
- [ ] Interview subset of participants about decision experience
- [ ] Analyze preliminary patterns in decision quality

### Phase 4: Long-term Follow-up (Months 13-24)
- [ ] 18-month comprehensive outcome assessment
- [ ] Career pathway and satisfaction evaluation
- [ ] Final statistical analysis and model testing

## Statistical Analysis Plan
- **Primary Analysis**: 3x3 factorial ANOVA with planned contrasts testing linear and quadratic information effects
- **Secondary Analysis**: Mediation analysis examining cognitive load as mediator between information condition and satisfaction
- **Exploratory Analysis**: Machine learning approaches to identify optimal information presentation patterns

## Expected Impact
This experiment directly tests a fundamental assumption in college advising and information design. Results could:
- Revolutionize college website design and information architecture
- Change how academic advisors structure major exploration conversations
- Influence development of decision support tools across higher education
- Challenge the "more information is better" paradigm in educational decision-making

## Risk Mitigation
- **Ethical concerns**: All information provided will be accurate; we're varying quantity/format, not quality
- **Attrition risk**: Multiple touchpoints and incentive structure to maintain engagement
- **Confounding variables**: Control for prior knowledge, academic preparation, and demographic factors
- **Implementation challenges**: Partner with registrar and advising offices for institutional support

## Resource Requirements
- Research team: 2 graduate students, 1 postdoc, PI supervision
- Technology: Online platform development and eye-tracking equipment (subset)
- Participant incentives: $50 per student for completion of all assessments
- IRB compliance and data management infrastructure

## Broader Research Context
This experiment serves as a critical test of information processing assumptions in educational decision-making, building on choice overload research (Iyengar & Lepper, 2000) while extending it to consequential life decisions. Results will inform our broader research program on challenging literature-level assumptions about college major choice processes.